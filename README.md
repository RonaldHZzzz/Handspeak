<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>README - HaandSpeak</title>
</head>
<body>
    <h1>HaandSpeak</h1>
    <p>
        <strong>HaandSpeak</strong> es una aplicaci√≥n dise√±ada para facilitar la comunicaci√≥n entre personas sordas o 
        con discapacidad auditiva y aquellos que no conocen el lenguaje de se√±as. Utilizando tecnolog√≠as avanzadas como 
        <strong>MediaPipe</strong>, <strong>YOLOv8</strong>, y <strong>Google Text-to-Speech (gTTS)</strong>, este proyecto 
        permite traducir gestos en texto o voz, promoviendo la inclusi√≥n y la igualdad de acceso a la informaci√≥n.
    </p>
    <h2>üìã Objetivo</h2>
    <p>
        El principal objetivo de <strong>HaandSpeak</strong> es proporcionar una herramienta inclusiva que:
    </p>
    <ul>
        <li>Traduzca el lenguaje de se√±as a texto o voz en tiempo real.</li>
        <li>Facilite la interacci√≥n en diversas situaciones, como educaci√≥n, atenci√≥n m√©dica y conversaciones diarias.</li>
        <li>Empodere a las personas con discapacidad auditiva con un recurso accesible y eficaz.</li>
    </ul>
    <h2>‚öôÔ∏è Caracter√≠sticas</h2>
    <ul>
        <li><strong>Reconocimiento de gestos:</strong> Utiliza MediaPipe para identificar movimientos espec√≠ficos de las manos.</li>
        <li><strong>Traducci√≥n de gestos a texto:</strong> Procesa los gestos y los convierte en texto comprensible.</li>
        <li><strong>Salida de voz:</strong> Convierte texto en voz utilizando Google Text-to-Speech.</li>
        <li><strong>Interfaz personalizable:</strong> Permite cambiar el color de fondo para mejorar la experiencia del usuario.</li>
        <li><strong>Gesti√≥n de la c√°mara:</strong> Funciones de refrescar y apagar para una mayor comodidad.</li>
    </ul>
    <h2>üöÄ Instalaci√≥n</h2>
    <h3>Requisitos previos</h3>
    <ul>
        <li>Python 3.7 o superior.</li>
        <li>Un editor de c√≥digo (por ejemplo, <a href="https://code.visualstudio.com/" target="_blank">Visual Studio Code</a>).</li>
    </ul>
    <h3>Pasos para instalar</h3>
    <ol>
        <li><strong>Instalar Python y Visual Studio Code.</strong> 
            <ul>
                <li>Descarga Python desde <a href="https://www.python.org/" target="_blank">python.org</a>.</li>
                <li>Instala Visual Studio Code desde <a href="https://code.visualstudio.com/" target="_blank">code.visualstudio.com</a>.</li>
            </ul>
        </li>
        <li><strong>Descargar el proyecto.</strong> 
            <p>Descarga el proyecto desde 
                <a href="https://drive.google.com/drive/folders/1vIgBe4wN0_2x2lSLQuke2oDvEv-NSnKv" target="_blank">esta URL</a>.
            </p>
        </li>
        <li><strong>Acceder al proyecto.</strong>
            <ul>
                <li>Abre Visual Studio Code, selecciona <code>File > Open Folder</code>, y localiza la carpeta del proyecto.</li>
            </ul>
        </li>
        <li><strong>Levantar entorno virtual.</strong>
            <pre>
pip install virtualenv
virtualenv venv
source venv/bin/activate   # Para Linux/MacOS
.\venv\Scripts\activate    # Para Windows
            </pre>
        </li>
        <li><strong>Instalar dependencias.</strong>
            <pre>
pip install -r requirements.txt
            </pre>
        </li>
        <li><strong>Ejecutar el programa.</strong>
            <ol>
                <li>Ve a la carpeta <code>app</code>:
                    <pre>cd app</pre>
                </li>
                <li>Inicia la aplicaci√≥n:
                    <pre>python app.py</pre>
                </li>
            </ol>
        </li>
    </ol>
    <h2>üìñ Uso</h2>
    <ol>
        <li>Col√≥cate frente a la c√°mara y realiza la se√±a que deseas traducir.</li>
        <li>El programa interpretar√° el gesto, lo convertir√° a texto, y lo reproducir√° como voz.</li>
        <li>Puedes cambiar el color de fondo y refrescar o apagar la c√°mara seg√∫n sea necesario.</li>
    </ol>
    <h2>üìö Tecnolog√≠as utilizadas</h2>
    <ul>
        <li><a href="https://flask.palletsprojects.com/" target="_blank">Flask</a> como framework principal.</li>
        <li><a href="https://mediapipe.dev/" target="_blank">MediaPipe</a> para el reconocimiento de gestos.</li>
        <li><a href="https://github.com/ultralytics/yolov8" target="_blank">YOLOv8</a> para detecci√≥n de objetos.</li>
        <li><a href="https://pypi.org/project/gTTS/" target="_blank">Google Text-to-Speech (gTTS)</a> para la generaci√≥n de voz.</li>
    </ul>
    <h2>üõ†Ô∏è Pr√≥ximos pasos</h2>
    <ul>
        <li>Ampliar el reconocimiento de se√±as.</li>
        <li>Soporte para m√∫ltiples idiomas.</li>
        <li>Optimizaci√≥n del rendimiento en dispositivos m√≥viles.</li>
    </ul>
    <h2>ü§ù Contribuciones</h2>
    <p>
        ¬°Contribuciones, reportes de errores, y sugerencias son bienvenidos! Por favor, abre un issue o env√≠a un pull request.
    </p>
    <h2>üìÑ Licencia</h2>
    <p>Este proyecto est√° bajo la Licencia MIT. Consulta el archivo <code>LICENSE</code> para m√°s detalles.</p>
</body>
</html>
